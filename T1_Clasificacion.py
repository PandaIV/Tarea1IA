# -*- coding: utf-8 -*-
"""Final T1_Clasificacion .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pxh0wHYUtfbNN55JwkVTPyMa5XUZ_hsT

# Milk Quality Prediction

Para comenzar se tienen datos de las cualidades de la leche que se clasifican en grado alto, medio y bajo de calidad.

## Dataset utilizado
Se utiliza de kaggle https://www.kaggle.com/datasets/cpluzshrijayan/milkquality
"""

import pandas as pd 
import numpy as np

#Input data files from a github link 
url = 'https://raw.githubusercontent.com/MissCella/Laboratorio1-IA/main/milknew.csv'
df = pd.read_csv(url)
df.sample(5)

df.shape

"""## Preparación de los datos

**Revisión de datos nulos.**
"""

df.isnull().sum()

"""No existen datos nulos en el dataset.

**Clasificar el grado en un valor numerico**

Se separa la columna de la clasificación de los datos.
"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical


X = df.drop(['Grade'], axis=1)
X = np.array(X)
Y = np.array(df['Grade'])

#Por si gusta ver somo se separaron los datos:
#X[:10], Y[:10]

"""Se asigna un valor a cada categoría, siendo 2 'high', 1 'medium', 0 'low'.
Luego de esto, con la funcion de 'to_categorical()' se acomodan los datos en modo de array, donde la posicion del dato 1 es la categoria.
"""

l_encode = LabelEncoder()
l_encode.fit(Y)
Y[Y=='high'] = 2
Y[Y=='medium'] = 1
Y[Y=='low'] = 0
Y = to_categorical(Y)

Y[:10]

"""**Train/test split**

Se separan los datos de entramiento y prueba, utilizando 20% de los datos para prueba. Se utiliza el 20% de los datos para hacer pruebas y verificar los resultados de la operación de la red neuronal con una matriz de confusión.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, Y, 
    test_size=0.2, random_state=42
)


X_train.shape, X_test.shape

y_test

"""**Escalar datos**

Se tienen datos de valores cercanos a cero, y otros con valores mayores a 200, esto puede confundir a la red y generar sobre-entrenamiento.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled[:4]

"""## Entrenamiento utilizando TensorFlow

*   Capa de salida: Se tienen 3 clasificaciones diferentes de grado, por lo que no se puede utilizar una única neurona de salida (que se utiliza para clasificación binaria), se deben utilizar al menos 3 neuronas de salida, para realizar una clasificación correcta.
*   Función de pérdida: Se utiliza Cross Entropy, pues es un caso de clasificación.
*   Class balance: ?

**Definición de la arquitectura de la red neuronal**


* 7 entradas
* Capas ocultas
* 3 neuronas de salida

La función de activación en cada capa será la sigmoide.
Tasa de aprendizaje de 0.01 para comenzar.
"""

import tensorflow as tf
tf.random.set_seed(42)

in_dim = len(df.columns)-1

model = tf.keras.Sequential([
    tf.keras.layers.Dense(7, input_dim = in_dim, activation='sigmoid'),
    tf.keras.layers.Dense(4, activation='sigmoid'),
    tf.keras.layers.Dense(3, activation='sigmoid')
])

model.compile(
    loss="categorical_crossentropy",
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))

"""Se evita utilizar la métrica de "accuracy", puesto que es el complemento de "loss"."""

history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100)

"""**Visualización del desemepeño de la red el entrenamiento**"""

import matplotlib.pyplot as plt
from matplotlib import rcParams

rcParams['figure.figsize'] = (18, 8)
rcParams['axes.spines.top'] = False
rcParams['axes.spines.right'] = False

plt.plot(
    #Valor del np arange debe ser epoch + 1
    np.arange(1, 101), 
    history.history['loss'], label='Training Loss'
)
plt.plot(
    #Valor del np arange debe ser epoch + 1
    np.arange(1, 101), 
    history.history['val_loss'], label='Test Loss'
)

plt.title('Evaluation metrics', size=20)
plt.xlabel('Epoch', size=14)
plt.legend();

"""Estamos sobre entrenando?

**Predicciones**
"""

predictions = model.predict(X_test_scaled)
predictions

"""Entes de evaluarlos se convierten en clases, si la probabilidad es mayor a 0.5 en una posición específica del array:


*   i[0] = 1 : el grado de la leche es low
*   i[1] = 1 : el grado de la leche es medium
*   i[2] = 1 : el grado de la leche es high


"""

predictions = np.where(predictions > 0.5, 1, predictions)
predictions = np.where(predictions != 1, 0, predictions)
predictions_final = np.around(predictions)

predictions_final

"""**Test Datos**

Matriz de confusión 3 x 3
"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(y_test.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(y_test, predictions_final, target_names=['low', 'medium', 'high']))

"""## 2.a Resultado esperado

**Importar datos**
"""

import pandas as pd 
import numpy as np

#Input data files from a github link 
url = 'https://raw.githubusercontent.com/MissCella/Laboratorio1-IA/main/DatosCLA.csv'
test_data = pd.read_csv(url)
test_data

"""**Escalar datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(test_data)

test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

predictions_final

"""## 2.b Clasificación de las variables de entrada en función de su sensibilidad

Para esta sección se utilizarán datos de prueba con sus respectuvos valores de salida para luego comparar el resultado obtenido.

### **Verificacion del funcionamiento con valores de entrada sin altera**r

**Obtención de los datos**
"""

import pandas as pd 
import numpy as np

#Input data files from a github link 
url = 'https://raw.githubusercontent.com/MissCella/Laboratorio1-IA/main/milknew.csv'
dfs = pd.read_csv(url)
dfs.sample(5)

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = dfs.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(dfs['Grade'])

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Aumentando el valor del **pH**

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_plus_ph = dfs
df_plus_ph['pH'] = (dfs['pH'] + dfs['pH']*2/100)
#df_plus_ph['pH']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_plus_ph.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_plus_ph['Grade'])
Xs

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Disminuyendo el valor del **pH**

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_less_ph = dfs
df_less_ph['pH'] = (dfs['pH'] - dfs['pH']*2/100)
#df_less_ph['pH']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_less_ph.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_less_ph['Grade'])
Xs

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Aumentando el valor de **Temperatura**

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_plus_Temperature = dfs
df_plus_Temperature['Temperature'] = (dfs['Temperature'] + dfs['Temperature']*10/100)
#df_plus_Temperature['Temperature']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_plus_Temperature.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_plus_Temperature['Grade'])
Xs

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Disminuyendo el valor de **Temperatura**

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_less_Temperature = dfs
df_less_Temperature['Temperature'] = (dfs['Temperature'] - dfs['Temperature']*2/100)
#df_less_Temperature['Temperature']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_less_Temperature.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_less_Temperature['Grade'])
Xs

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Taste** en 1

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_1_Taste = dfs
df_1_Taste['Taste'] = 1
#df_1_Taste['Taste']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_1_Taste.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_1_Taste['Grade'])
Xs

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Taste** en 0

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_0_Taste = dfs
df_0_Taste['Taste'] = 0
#df_0_Taste['Taste']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_0_Taste.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_0_Taste['Grade'])
Xs[:10]

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Odor** en 1

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_1_Odor = dfs
df_1_Odor['Odor'] = 1
#df_1_Odor['Odor']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_1_Odor.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_1_Odor['Grade'])
Xs[:10]

"""**Predicciones**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)


#Escalar los datos
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#predicciones
predictions = model.predict(test_data_scaled)
predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Odor** en 0

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_0_Odor = dfs
df_0_Odor['Odor'] = 0
#df_0_Odor['Odor']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_0_Odor.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_0_Odor['Grade'])
Xs[:10]

"""**Predicciones**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)


#Escalar los datos
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#predicciones
predictions = model.predict(test_data_scaled)
predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Fat** en 1

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_1_Fat = dfs
df_1_Fat['Fat '] = 1
#df_1_Fat['Fat']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_1_Fat.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_1_Fat['Grade'])
Xs[:10]

"""**Predicciones**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)


#Escalar los datos
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#predicciones
predictions = model.predict(test_data_scaled)
predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Fat** en 0

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_0_Fat = dfs
df_0_Fat['Fat '] = 0
#df_0_Fat['Fat']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_0_Fat.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_0_Fat['Grade'])
Xs[:10]

"""**Predicciones**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)


#Escalar los datos
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#predicciones
predictions = model.predict(test_data_scaled)
predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Turbidity** en 1

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_1_Turbidity = dfs
df_1_Turbidity['Turbidity'] = 1
#df_1_Turbidity['Turbidity']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_1_Turbidity.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_1_Turbidity['Grade'])
Xs[:10]

"""**Predicciones**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)


#Escalar los datos
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#predicciones
predictions = model.predict(test_data_scaled)
predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Valores de **Turbidity** en 0

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_0_Turbidity = dfs
df_0_Turbidity['Turbidity'] = 0
#df_0_Turbidity['Turbidity']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_0_Turbidity.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_0_Turbidity['Grade'])
Xs[:10]

"""**Predicciones**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)


#Escalar los datos
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#predicciones
predictions = model.predict(test_data_scaled)
predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Aumentando el valor del **Colour**

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_plus_colour = dfs

#Valores mayores a 255 se redondean a 255 puesto que este es el valor mayor
df_plus_colour['Colour'] = (dfs['Colour'] + dfs['Colour']*6/100)
df_plus_colour['Colour'][df_plus_colour['Colour']>255] = 255

#df_plus_colour['Colour']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_plus_colour.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_plus_colour['Grade'])
Xs[:10]

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))

"""### Disminuyendo el valor del **Colour**

**Obtención de los datos**
"""

dfs = pd.read_csv(url)
df_plus_colour = dfs

#Valores menores a 240 se redondean a 240 puesto que este es el valor menor
df_plus_colour['Colour'] = (dfs['Colour'] - dfs['Colour']*6/100)
df_plus_colour['Colour'][df_plus_colour['Colour']<240] = 240

#df_plus_colour['Colour']

"""**Separación de los datos de entrada de los de salida**"""

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical

Xs = df_plus_colour.drop(['Grade'], axis=1)
Xs = np.array(Xs)
Ys = np.array(df_plus_colour['Grade'])
Xs[:10]

"""**Se codifican los datos**"""

l_encode = LabelEncoder()
l_encode.fit(Ys)
Ys[Ys=='high'] = 2
Ys[Ys=='medium'] = 1
Ys[Ys=='low'] = 0
Ys = to_categorical(Ys)

#Ys[:10]

"""**Escalar los datos**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_data_scaled = scaler.fit_transform(Xs)

#test_data_scaled[:4]

"""**Predicciones**"""

predictions = model.predict(test_data_scaled)
#predictions

predictions_round = np.where(predictions > 0.5, 1, predictions)
predictions_round = np.where(predictions_round != 1, 0, predictions_round)
predictions_final = np.around(predictions_round)

#predictions_final

"""**Matrix de confusion**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Plot the confusion matrix
cm = confusion_matrix(Ys.argmax(axis=1), predictions_final.argmax(axis=1))

dict_live = { 
    0 : 'low',
    1 : 'medium',
    2 : 'high'
}

df_cm = pd.DataFrame(cm, index = [dict_live[i] for i in range(0,3)], columns = [dict_live[i] for i in range(0,3)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()

from sklearn.metrics import classification_report

print('\nClassification Report\n')
print(classification_report(Ys, predictions_final, target_names=['low', 'medium', 'high']))