# -*- coding: utf-8 -*-
"""Ambos Vinos T1_Regresión.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k_ZXhC14zSALabilWV7kGk7DJ-iQCMe8

FUENTE: https://www.tensorflow.org/tutorials/keras/regression?hl=es-419
"""

## Importación de Librerías ##
# Se usan librerías para lectura de archivos, funciones matemáticas, graficar y 
# de redes neuronales.
import pandas as pd 
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
import random



## Lectura de Archivos ##
# Tambien se imprime 5 datos para poder visualizarlos mejor.
df1 = pd.read_csv('winequality-white.csv')
df2 = pd.read_csv('winequality-red.csv')
print(df1.shape)
print(df2.shape)
# Para unir ambos archivos
df3 = pd.concat([df1, df2])
print(df3.shape)
# Para mezclar y aleatorizar los datos
df = df3.sample(frac = 1)
print(df.shape)

df.sample(5)

## Se imprimen algunos valores importantes para analisis de datos ##
print("Data Set Shape: ", df.shape, '\n')
print("Valores vacios en datos:\n", df.isnull().sum(),'\n')
print("Numero de datos por calidad:\n", df['quality'].value_counts(),'\n')

## Se separan los datos en etiquetas y caracteristicas ##
# Para las caracteristicas (x) se elimina la columna de calidad y se toma como 
# etiquetas (y) esa columna
X = df.drop('quality', axis=1)
y = df['quality']


## Se separan los datos en 80% entrenamiento y 20% prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, random_state=42
)

X_train.shape, X_test.shape


## Se usa la libreria de sklearn.preprocessing para poder escalar los datos.

## Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

## Se crea el modelo de red neuronal clasica ##

# Se utilizan 20 Neuronas - 96 Neuronas - 1 Salida
regression_model = tf.keras.Sequential([
    tf.keras.layers.Dense(20, activation='sigmoid', input_shape=[len(X_train.keys())]),
    tf.keras.layers.Dense(20, activation='sigmoid'),
    tf.keras.layers.Dense(1)
])

# Se compila este modelo utilizando una funcion de perdida de MeanSquaredError
# Ademas un optimizador RMSprop con tasa de aprendizaje de 0.001
regression_model.compile(loss="huber", optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['mae', 'mse'])

regression_model.summary()


## Se configuran 200 epocas
EPOCHS = 200

## Se entrena el modelo y con los datos de entrenamiento se hace otra division,
# Se usan 20% de estos datos para la validación.
history = regression_model.fit(X_train_scaled , y_train, epochs=EPOCHS, validation_split = 0.2)

## Se imprime el histrial para ver los ultimos valores importantes del entrenamiento
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

## Función para graficar facilmente

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Huber Error')
  plt.plot(hist['epoch'], hist['loss'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_loss'],
           label = 'Val Error')
  plt.ylim([0,2])
  plt.legend()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$MPG^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.ylim([0,10])
  plt.legend()
  plt.show()

## Se imprime las graficas de perdida con suma cuadrada del error y con
# suma absoluta del error. 
plot_history(history)

## Luego se hace la evaluación del modelo con los datos de prueba 
loss, mae, mse = regression_model.evaluate(X_test_scaled, y_test, verbose=2)

## Se observa los resultados obtenidos
print("Testing set Mean Abs Error: {:5.2f} MPG".format(mae))

## Finalmente se hace uso de los datos de prueba para la predicción.
test_predictions = regression_model.predict(X_test_scaled).flatten()

## Se grafica la tabla de valores y predicciones.
plt.scatter(y_test, test_predictions)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])

## Finalmente para otra manera de observar los resultados se hace un histograma
error = test_predictions - y_test
plt.hist(error, bins = 8)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

## Se grafica la tabla de valores y predicciones.
plt.scatter(y_test, np.round(test_predictions))
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])


## Se redondean los resultados para mejor visualizacion
round_error = np.round(test_predictions) - y_test
print(max(round_error))
print(min(round_error))

## Observar diferentes valores unicos de error presentes
output = []
for x in round_error:
    if x not in output:
        output.append(x)
print(output)

## Se hace un histograma con los errores redondeados
plt.hist(round_error, bins = 6)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

## Utilizado para ver cantidad de errores unicos
from collections import Counter
c = Counter(round_error)
print(c)

## Prueba de valores esperados tarea
x_work = pd.read_csv('combinedwine_test.csv')
x_work.sample(6)

## Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
x_work_scaled = scaler.fit_transform(x_work)

## Se hace la prediccion y se imprime y redondeada
work_predictions = regression_model.predict(x_work_scaled).flatten()
print(work_predictions)
print(np.round(work_predictions))