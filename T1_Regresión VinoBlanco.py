# -*- coding: utf-8 -*-
"""T1_Regresión.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KuwirJmC8gzI5QPfwW6c02dsY2FsM0ag

# Entrenamiento y Prueba de Modelo

FUENTE: https://www.tensorflow.org/tutorials/keras/regression?hl=es-419
"""

## Importación de Librerías ##
# Se usan librerías para lectura de archivos, funciones matemáticas, graficar y 
# de redes neuronales.
import pandas as pd 
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf


## Lectura de Archivos ##
# Tambien se imprime 5 datos para poder visualizarlos mejor.
df = pd.read_csv('winequality-white.csv')
df.sample(5)

## Se imprimen algunos valores importantes para analisis de datos ##
print("Data Set Shape: ", df.shape, '\n')
print("Valores vacios en datos:\n", df.isnull().sum(),'\n')
print("Numero de datos por calidad:\n", df['quality'].value_counts(),'\n')

## Se separan los datos en etiquetas y caracteristicas ##
# Para las caracteristicas (x) se elimina la columna de calidad y se toma como 
# etiquetas (y) esa columna
X = df.drop('quality', axis=1)
y = df['quality']


## Se separan los datos en 80% entrenamiento y 20% prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, random_state=42
)

X_train.shape, X_test.shape

## Se usa la libreria de sklearn.preprocessing para poder escalar los datos.

## Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

## Se crea el modelo de red neuronal clasica ##

# Se utilizan 16 Neuronas - 16 Neuronas - 16 Neuronas - 1 Salida
regression_model = tf.keras.Sequential([
    tf.keras.layers.Dense(16, activation='sigmoid', input_shape=[len(X_train.keys())]),
    tf.keras.layers.Dense(16, activation='sigmoid'),
    tf.keras.layers.Dense(16, activation='sigmoid'),
    tf.keras.layers.Dense(1)
])

# Se compila este modelo utilizando una funcion de perdida de MeanSquaredError
# Ademas un optimizador RMSprop con tasa de aprendizaje de 0.001
regression_model.compile(loss="huber", optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['mae', 'mse'])

regression_model.summary()

## Se configuran 200 epocas
EPOCHS = 200

## Se entrena el modelo y con los datos de entrenamiento se hace otra division,
# Se usan 20% de estos datos para la validación.
history = regression_model.fit(X_train_scaled , y_train, epochs=EPOCHS, validation_split = 0.2)

## Se imprime el histrial para ver los ultimos valores importantes del entrenamiento
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

## Función para graficar facilmente

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Huber Error')
  plt.plot(hist['epoch'], hist['loss'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_loss'],
           label = 'Val Error')
  plt.ylim([0,2])
  plt.legend()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$MPG^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.ylim([0,10])
  plt.legend()
  plt.show()

## Se imprime las graficas de perdida con suma cuadrada del error y con
# suma absoluta del error. 
plot_history(history)

## Luego se hace la evaluación del modelo con los datos de prueba 
loss, mae, mse = regression_model.evaluate(X_test_scaled, y_test, verbose=2)

## Se observa los resultados obtenidos
print("Testing set Mean Abs Error: {:5.2f} MPG".format(mae))

## Finalmente se hace uso de los datos de prueba para la predicción.
test_predictions = regression_model.predict(X_test_scaled).flatten()

## Se grafica la tabla de valores y predicciones.
plt.scatter(y_test, test_predictions)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])

## Finalmente para otra manera de observar los resultados se hace un histograma
error = test_predictions - y_test
plt.hist(error, bins = 8)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

## Se grafica la tabla de valores y predicciones con valores redondeados.
plt.scatter(y_test, np.round(test_predictions))
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])

## Se redondean los resultados para mejor visualizacion
round_error = np.round(test_predictions) - y_test
print(max(round_error))
print(min(round_error))

## Observar diferentes valores unicos de error presentes
output = []
for x in round_error:
    if x not in output:
        output.append(x)
print(output)

## Se hace un histograma con los errores redondeados
plt.hist(round_error, bins = 6)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

## Utilizado para ver cantidad de errores unicos
from collections import Counter
c = Counter(round_error)
print(c)

## Prueba de valores esperados tarea
x_work = pd.read_csv('winequality-white - resultadoesperado.csv')
x_work.sample(3)

## Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
x_work_scaled = scaler.fit_transform(x_work)

## Se hace la prediccion y se imprime y redondeada
work_predictions = regression_model.predict(x_work_scaled).flatten()
print(work_predictions)
print(np.round(work_predictions))

"""# Sensibilidad de Entradas

### **Verificacion del funcionamiento con valores de entrada sin alterar**

A continuación se evaluarán todos los datos provistos por el profesor en el dataset.

**Ingreso de los datos a evluar**
"""

#Datos del github
df = pd.read_csv('winequality-white.csv')
X = df
df.sample(5)
df.shape

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **fixed acidity**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'fixed acidity'
porcentaje = 20

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] + df[variable]*porcentaje/100)
df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **volatile acidity**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'volatile acidity'
porcentaje = 50

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] + df[variable]*porcentaje/100)
df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **citric acid**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'citric acid'
porcentaje = 20
#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] + df[variable]*porcentaje/100)
df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **residual sugar**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'residual sugar'
porcentaje = 70

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] + df[variable]*porcentaje/100)
df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **chlorides**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 
df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'chlorides'
porcentaje = 20

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] - df[variable]*porcentaje/100)
df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **free_sulfur_dioxide**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 
df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'free sulfur dioxide'
porcentaje = 20

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] + df[variable]*porcentaje/100)

df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **total_sulfur_dioxide**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'free sulfur dioxide'
porcentaje = 50

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] - df[variable]*porcentaje/100)

df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **density**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'density'
porcentaje = 50

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] - df[variable]*porcentaje/100)

df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **pH**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'pH'
porcentaje = 20

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] + df[variable]*porcentaje/100)

df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **sulphates**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 
df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'sulphates'
porcentaje = 50

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] - df[variable]*porcentaje/100)

df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)

"""### Alteración de los valores del **alcohol**

**Ingreso de los datos a evluar**
"""

#En cada iteracion se definen los datos de nuevo para que no se pierda la informacion 
#SIEMPRE CORRER ESTAS LINEAS PRIMERO 

df = pd.read_csv('winequality-white.csv')
X = df
df

"""**Alteracion de la variable**"""

#Ingresar el valor x del porcentaje  x% (entre 1 y 100, o menor si desea menor, no se depende de la persona)
variable = 'alcohol'
porcentaje = 50

#Aca se puede variar si se suma o resta el porcentaje propuesto
df[variable] = (df[variable] - df[variable]*porcentaje/100)

df

"""**Separación de los datos de calidad**"""

X = df.drop('quality', axis=1)
y = df['quality']

"""**Escalación de los datos**"""

# Cada caracteristica se escala a una variacion de la unidad.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled

"""**Predicciones**"""

## Se realizan las predicciones sobre los valores provistos
test_predictions = regression_model.predict(X_scaled).flatten()

#Grafica de las predicciones
plt.scatter(y, np.round(test_predictions))
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.grid()

"""**Comparacion de los valores redondeados**"""

round_error = np.round(test_predictions) - y

plt.hist(round_error, bins = 7)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""**Errores**"""

from collections import Counter
c = Counter(round_error)
print(c)